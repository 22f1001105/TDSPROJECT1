{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n86ieC6bNnK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Set up your GitHub API token\n",
        "api_token = input(\"Enteer API Token: \")\n",
        "headers = {'Authorization': f'token {api_token}'}\n",
        "\n",
        "# Function to fetch users\n",
        "def fetch_users():\n",
        "    users_data = []\n",
        "    page = 1\n",
        "    while True:\n",
        "        users_url = f\"https://api.github.com/search/users?q=location:Dublin+followers:>50&page={page}&per_page=100\"\n",
        "        response = requests.get(users_url, headers=headers)\n",
        "        data = response.json()\n",
        "        if 'items' not in data or not data['items']:\n",
        "            break\n",
        "        users_data.extend(data['items'])\n",
        "        page += 1\n",
        "        time.sleep(1)  # Avoid hitting rate limits\n",
        "    return users_data\n",
        "\n",
        "# Get detailed user info\n",
        "def get_user_details(users_data):\n",
        "    users = []\n",
        "    for user in users_data:\n",
        "        user_response = requests.get(user['url'], headers=headers)\n",
        "        user_info = user_response.json()\n",
        "\n",
        "        company = user_info.get('company', '')\n",
        "        if company:\n",
        "            company = company.strip().lstrip('@').upper()\n",
        "\n",
        "        users.append({\n",
        "            'login': user_info['login'],\n",
        "            'name': user_info.get('name', ''),\n",
        "            'company': company,\n",
        "            'location': user_info.get('location', ''),\n",
        "            'email': user_info.get('email', ''),\n",
        "            'hireable': 'true' if user_info.get('hireable') else 'false',\n",
        "            'bio': user_info.get('bio', ''),\n",
        "            'public_repos': user_info.get('public_repos', 0),\n",
        "            'followers': user_info.get('followers', 0),\n",
        "            'following': user_info.get('following', 0),\n",
        "            'created_at': user_info.get('created_at', '')\n",
        "        })\n",
        "        time.sleep(0.5)  # Slow down requests slightly to avoid rate limits\n",
        "    return users\n",
        "\n",
        "# Function to fetch repositories\n",
        "def fetch_repos(users):\n",
        "    repos = []\n",
        "    for user in users:\n",
        "        page = 1\n",
        "        user_repos = []\n",
        "        while True:\n",
        "            repos_url = f\"https://api.github.com/users/{user['login']}/repos?sort=pushed&direction=desc&page={page}&per_page=100\"\n",
        "            repos_response = requests.get(repos_url, headers=headers)\n",
        "            repos_data = repos_response.json()\n",
        "\n",
        "            if not repos_data or len(user_repos) >= 500:\n",
        "                break\n",
        "\n",
        "            for repo in repos_data:\n",
        "                if len(user_repos) >= 500:\n",
        "                    break\n",
        "                user_repos.append({\n",
        "                    'login': user['login'],\n",
        "                    'full_name': repo.get('full_name', ''),\n",
        "                    'created_at': repo.get('created_at', ''),\n",
        "                    'stargazers_count': repo.get('stargazers_count', 0),\n",
        "                    'watchers_count': repo.get('watchers_count', 0),\n",
        "                    'language': repo.get('language', ''),\n",
        "                    'has_projects': 'true' if repo.get('has_projects') else 'false',\n",
        "                    'has_wiki': 'true' if repo.get('has_wiki') else 'false',\n",
        "                    'license_name': repo['license']['name'] if repo.get('license') else ''\n",
        "                })\n",
        "            page += 1\n",
        "            time.sleep(1)  # Avoid rate limit issues\n",
        "        repos.extend(user_repos)\n",
        "    return repos\n",
        "\n",
        "# Main execution\n",
        "users_data = fetch_users()\n",
        "users = get_user_details(users_data)\n",
        "repos = fetch_repos(users)\n",
        "\n",
        "# Save to CSV\n",
        "users_df = pd.DataFrame(users)\n",
        "users_df.to_csv('users.csv', index=False)\n",
        "repos_df = pd.DataFrame(repos)\n",
        "repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "print(\"Data scraping and file creation completed.\")\n"
      ]
    }
  ]
}